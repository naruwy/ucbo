{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1702044418868,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"9chm3EbraQGh","outputId":"d4bae624-d494-4855-a998-de8bb9293bf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Dec  8 14:06:57 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702044418868,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"q4Wrt7dVjemI","outputId":"1e4454dc-9e3e-4ffb-a68c-47ab93292e76"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":2}],"source":["# prompt: CPUのコア数をしらべて\n","import os\n","os.cpu_count()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702044418868,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"z7YNmSGL1p_5"},"outputs":[],"source":["class Config:\n","    name = \"exp042\" # 実験のたびにコピーしてここの名前を変えて実行するとoutputが別のファイルに保存される\n","\n","    # Colab Env\n","    upload_from_colab = False\n","    api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\"\n","    drive_path = \"/content/drive/MyDrive/kaggle/ucbo\"\n","\n","DEBUG = False\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702044418869,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"VbXtfty816RE"},"outputs":[],"source":["import os\n","import json\n","import warnings\n","import shutil\n","import logging\n","import joblib\n","import random\n","import datetime\n","import sys\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2575,"status":"ok","timestamp":1702044421440,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"LhXvf-UB16Ol","outputId":"4dfcced9-0710-4ce4-8594-a7faa7eeb875"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kaggle\n","  Downloading kaggle-1.5.16.tar.gz (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110683 sha256=de862fab59beb04c6c75f1fcd2bd28c6defde73dd11bb2a818f9742176f5dd7b\n","  Stored in directory: /root/.cache/pip/wheels/43/4b/fb/736478af5e8004810081a06259f9aa2f7c3329fc5d03c2c412\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.16\n","    Uninstalling kaggle-1.5.16:\n","      Successfully uninstalled kaggle-1.5.16\n","Successfully installed kaggle-1.5.16\n"]}],"source":["COLAB = \"google.colab\" in sys.modules\n","!pip install --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82126,"status":"ok","timestamp":1702044503561,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"1YQXcS4z16IF","outputId":"905061a9-d8d0-418f-fde4-d93c64cea2ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["This environment is Google Colab\n","Mounted at /content/drive\n"]}],"source":["if COLAB:\n","    print(\"This environment is Google Colab\")\n","\n","    # mount\n","    from google.colab import drive\n","    if not os.path.isdir(\"/content/drive\"):\n","        drive.mount('/content/drive')\n","\n","\n","    # use kaggle api (need kaggle token)\n","    f = open(Config.api_path, 'r')\n","    json_data = json.load(f)\n","    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n","\n","    # set dirs\n","    DRIVE = Config.drive_path\n","    EXP = Config.name\n","    INPUT = os.path.join(DRIVE, \"Input\")\n","    OUTPUT = os.path.join(DRIVE, \"Output\")\n","    SCRIPT = os.path.join(DRIVE, \"Script\")\n","    OUTPUT_EXP = os.path.join(OUTPUT, EXP)\n","    # EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n","    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n","    # EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n","\n","    # make dirs\n","    for d in [INPUT, SCRIPT, OUTPUT, OUTPUT_EXP]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    # if not os.path.isfile(os.path.join(INPUT, \"train.csv\")):\n","    #     # load dataset\n","    #     ! kaggle competitions download -c UBC-OCEAN -p $INPUT\n","    #     unzip_file = os.path.join(INPUT, 'UBC-OCEAN.zip')\n","    #     ! unzip $unzip_file -d $INPUT\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aSjd5Zqn9wk","outputId":"4130af47-8c10-40c0-d608-822c802c5730"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading ucbo-colab-dataset.zip to /content/tmp\n"," 95% 380M/399M [00:05<00:00, 113MB/s]\n","100% 399M/399M [00:05<00:00, 79.8MB/s]\n","Archive:  /content/tmp/ucbo-colab-dataset.zip\n","  inflating: /content/tmp/ucbo-colab-dataset/sample_submission.csv  \n","  inflating: /content/tmp/ucbo-colab-dataset/test.csv  \n","  inflating: /content/tmp/ucbo-colab-dataset/train.csv  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/13568.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/17637.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/21020.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/29084.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/31594.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/35565.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/36302.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/36583.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/36783.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/37385.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/40864.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/4134.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/41368.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/41586.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/42857.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/44603.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/47035.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/48734.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/50932.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/53655.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/57696.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/61797.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/8280.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/91.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/9200.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/updated_image_ids.json  \n","Downloading efficientnet-pytorch.zip to /content/tmp\n","100% 688M/688M [00:10<00:00, 118MB/s] \n","100% 688M/688M [00:10<00:00, 72.1MB/s]\n","Archive:  /content/tmp/efficientnet-pytorch.zip\n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/.gitignore  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/LICENSE  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/efficientnet_pytorch/__init__.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/efficientnet_pytorch/model.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/efficientnet_pytorch/utils.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/imagenet/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/imagenet/data/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/imagenet/main.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/check.ipynb  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/example.ipynb  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/img.jpg  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/img2.jpg  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/labels_map.txt  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/setup.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/download.sh  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/load_tf_weights.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/__init__.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/efficientnet_builder.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/efficientnet_model.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/eval_ckpt_main.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/preprocessing.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/utils.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/pretrained_tensorflow/download.sh  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b0-08094119.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b2-27687264.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b4-e116e8b3.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b5-586e6cc6.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b6-c76e70fd.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b7-dcc49843.pth  \n","Downloading tiles-of-cancer-2048px-scale-0-25.zip to /content/tmp\n"," 17% 8.58G/49.4G [01:48<08:45, 83.5MB/s]"]}],"source":["%%time\n","if not DEBUG:\n","    # tmp fileに直接ダウンロードする\n","    TMP = '/content/tmp'\n","    INPUT = '/content/tmp'\n","    !mkdir $TMP\n","    files = [\n","        'tyabanoamami/ucbo-colab-dataset', 'hmendonca/efficientnet-pytorch',\n","            #  'pjmathematician/ucbo-tiles-256-1', #'tyabanoamami/ucbo-clean-images',\n","            #  'pjmathematician/ucbo-tiles-256-2', 'pjmathematician/ucbo-tiles-256-3',\n","            #  'pjmathematician/ucbo-tiles-256-4', 'pjmathematician/ucbo-tiles-256-5',\n","        'jirkaborovec/tiles-of-cancer-2048px-scale-0-25'\n","            ]\n","    for f in files:\n","        !kaggle datasets download -d $f -p $TMP\n","        t = f.split('/')[1]\n","        unzip_file = os.path.join(TMP, f'{t}.zip')\n","        unzip_file_ = TMP + '/' + t\n","        INPUT_ = INPUT + '/' + t\n","        ! unzip $unzip_file -d $unzip_file_\n","        # !mv $unzip_file_ $INPUT_\n","        !rm -rf $unzip_file"]},{"cell_type":"markdown","metadata":{"id":"kP7MT0Q4mssZ"},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dc8KgsmmHvX"},"outputs":[],"source":["!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n","!pip install timm\n","\n","!pip install pytorch-metric-learning[with-hooks]\n","!pip install typing-extensions --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4yHEKWS9mF01"},"outputs":[],"source":["import os\n","import sys\n","sys.path = [\n","    os.path.join(INPUT, 'efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master'),\n","] + sys.path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysI2Fw9NjSMp"},"outputs":[],"source":["import time\n","import skimage.io\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import PIL.Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n","from warmup_scheduler import GradualWarmupScheduler\n","from efficientnet_pytorch import model as enet\n","import albumentations\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import cohen_kappa_score\n","from tqdm.notebook import tqdm\n","from sklearn.metrics import balanced_accuracy_score\n","import timm\n","import pytorch_metric_learning\n","from pytorch_metric_learning.losses import ArcFaceLoss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzV9WLBsNqQi"},"outputs":[],"source":["# df = pd.read_csv('/content/drive/MyDrive/kaggle/ucbo/Input/tiles-of-cancer-2048px-scale-0-25/train.csv')\n","# df[df.image_id==int(folders[1].split('/')[-1])].is_tma.values\n","# from glob import glob\n","# folders = glob('/content/drive/MyDrive/kaggle/ucbo/Input/tiles-of-cancer-2048px-scale-0-25/*')\n","# for f in sorted(folders, key=lambda x: int(x.split('/')[-1]) if x.split('/')[-1]!='train.csv' else 999999)[:-1]:\n","#     tma=False\n","#     if df[df.image_id==int(f.split('/')[-1])].is_tma.values[0]:\n","#         tma=True\n","#     print(f.split('/')[-1], len(glob(f+'/*png')), tma)"]},{"cell_type":"markdown","metadata":{"id":"tOGJTn-Zndmp"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnZ0bZndmKEa"},"outputs":[],"source":["data_dir = os.path.join(INPUT, 'tiles-of-cancer-2048px-scale-0-25')\n","df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","image_folder = os.path.join(data_dir, 'train_images')\n","labels = ['CC', 'EC', 'HGSC', 'LGSC', 'MC', 'Other'] #df_train['label'].unique().tolist() + ['Other']\n","l2n = {v: k for k, v in enumerate(labels)}\n","n2l = {k: v for k, v in enumerate(labels)}\n","\n","kernel_type = Config.name\n","\n","enet_type = 'efficientnet_b0'\n","fold = 0\n","tile_size = 512\n","image_size = 512\n","n_tiles = 4 if DEBUG else 9\n","batch_size = 4\n","num_workers = os.cpu_count()\n","out_dim = 5\n","init_lr = 3e-4\n","warmup_factor = 10\n","\n","warmup_epo = 1\n","n_epochs = 1 if DEBUG else 20\n","df_train = df_train.sample(100).reset_index(drop=True) if DEBUG else df_train\n","\n","device = torch.device('cuda')\n","\n","print(image_folder)\n","\n","import random\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","seed_torch()"]},{"cell_type":"markdown","metadata":{"id":"XKB0VzWDmyce"},"source":["# Create Folds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3mQXsADmPwK"},"outputs":[],"source":["skf = StratifiedKFold(5, shuffle=True, random_state=42)\n","df_train['fold'] = -1\n","for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['label'])):\n","    df_train.loc[valid_idx, 'fold'] = i\n","# df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJ08DLvlmPsr"},"outputs":[],"source":["def get_image_path(image_id:int):\n","    # if 4 <= image_id <= 15188:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-1')\n","    # elif 15209 <= image_id <= 30515:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-2')\n","    # elif 30539 <= image_id <= 38687:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-3')\n","    # elif 38849 <= image_id <= 65300:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-4')\n","    # elif 65371 <= image_id <= 65533:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-5')\n","    path = os.path.join(INPUT, 'tiles-of-cancer-2048px-scale-0-25')\n","    return os.path.join(path, str(image_id))\n","\n","df_train['tile_path'] = df_train['image_id'].apply(lambda x: get_image_path(x))\n","\n","# df_train['total_tiles'] = df_train['tile_path'].apply(lambda x: len(os.listdir(x)))\n","# df_train.head()\n","\n","# train['clean_tiles'] = train['image_id'].apply(lambda x: len(d[x]))/train['total_tiles']\n","# train.head()"]},{"cell_type":"markdown","metadata":{"id":"vDeD5a4Am1xd"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iuIn2_4aqe-0"},"outputs":[],"source":["# prompt: class enetv2(nn.Module):     def __init__(self, backbone, out_dim):         super(enetv2, self).__init__()         self.enet = enet.EfficientNet.from_name(backbone)         self.enet.load_state_dict(torch.load(pretrained_model[backbone]))          self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)         self.enet._fc = nn.Identity()      def extract(self, x):         return self.enet(x)      def forward(self, x):         x = self.extract(x)         x = self.myfc(x)         return xこのモデルをtimmを使って書き直してください\n","\n","class enetv2(nn.Module):\n","    def __init__(self, backbone, out_dim):\n","        super(enetv2, self).__init__()\n","        self.enet = timm.create_model(backbone, pretrained=True)\n","        self.myfc = nn.Linear(self.enet.classifier.in_features, out_dim)\n","        self.enet.classifier = nn.Identity()\n","\n","    def extract(self, x):\n","        return self.enet(x)\n","\n","    def forward(self, x):\n","        x = self.extract(x)\n","        # x = self.myfc(x)\n","        return x\n","\n","\n","# class enetv2(nn.Module):\n","#     def __init__(self, backbone, out_dim):\n","#         super(enetv2, self).__init__()\n","#         self.enet = enet.EfficientNet.from_name(backbone)\n","#         self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n","\n","#         self.myfc = nn.Linear(self.enet._fc.in_features, out_dim) # (1280 => 6)\n","#         self.enet._fc = nn.Identity()\n","\n","#     def extract(self, x):\n","#         return self.enet(x)\n","\n","#     def forward(self, x):\n","#         x = self.extract(x)\n","# #         x = self.myfc(x) # arcface loss では封印\n","#         return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YeLRJnYsqrU"},"outputs":[],"source":["# model = enetv2('efficientnet_b0', 6)\n","# model = timm.create_model('efficientnet_b0', pretrained=True)\n","# model.__dict__['default_cfg']"]},{"cell_type":"markdown","metadata":{"id":"nJ5ihzXsm5CS"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APyXWUI6mPmD"},"outputs":[],"source":["import joblib\n","good_images = joblib.load(os.path.join(OUTPUT, 'bw_checker/good_images.pkl'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAfb99GJmPjE"},"outputs":[],"source":["def get_tiles(paths):\n","    ret = []\n","    for path in paths:\n","        # PNGファイルを読み込み\n","        image = PIL.Image.open(path)\n","\n","        # Pillow ImageオブジェクトをNumPy配列に変換\n","        image_array = np.array(image)\n","        ret.append(image_array)\n","    return ret\n","\n","\n","class PANDADataset(Dataset):\n","    def __init__(self,\n","                 df,\n","                 image_size,\n","                 n_tiles=n_tiles,\n","                 tile_mode=0,\n","                 rand=False,\n","                 transform=None,\n","                ):\n","\n","        self.df = df.reset_index(drop=True)\n","        self.image_size = image_size\n","        self.n_tiles = n_tiles\n","        self.tile_mode = tile_mode\n","        self.rand = rand\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img_id = row.image_id\n","\n","\n","        try:\n","            tiles = good_images[img_id]\n","        except:\n","            files = os.listdir(row.tile_path)\n","            tiles = [row.tile_path + f'/{e}' for e in files]\n","        if DEBUG:\n","            tiles = [t.replace('/content/tmp', INPUT) for t in tiles]\n","        n_imgs = len(tiles)\n","        tiles = get_tiles(tiles)\n","\n","\n","        if self.rand:\n","            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n","        else:\n","            idxes = list(range(self.n_tiles))\n","\n","        n_row_tiles = int(np.sqrt(self.n_tiles))\n","        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n","        for h in range(n_row_tiles):\n","            for w in range(n_row_tiles):\n","                i = h * n_row_tiles + w\n","\n","                # fill all tiles(exp014)\n","                try:\n","                    this_img = tiles[idxes[i%n_imgs]]\n","                except:\n","                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n","                # if len(tiles) > idxes[i]:\n","                #     this_img = tiles[idxes[i]]\n","                # else:\n","                #\n","                this_img = 255 - this_img\n","                if self.transform is not None:\n","                    this_img = self.transform(image=this_img)['image']\n","                h1 = h * image_size\n","                w1 = w * image_size\n","                images[h1:h1+image_size, w1:w1+image_size] = this_img\n","\n","        # if self.transform is not None:\n","        #     images = self.transform(image=images)['image']\n","        images = images.astype(np.float32)\n","        # images /= 255\n","        images = images.transpose(2, 0, 1)\n","\n","        # default label\n","        label = np.zeros(out_dim).astype(np.float32)\n","        label[l2n[row.label]] = 1.\n","\n","        #label smoothing(exp006)\n","        # eps = 0.05\n","        # label = np.ones(out_dim).astype(np.float32) * eps/out_dim\n","        # label[l2n[row.label]] += (1. - eps)\n","\n","        return torch.tensor(images), torch.tensor(label)\n"]},{"cell_type":"markdown","metadata":{"id":"aZ8pFL5cm9Ta"},"source":["# Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl_I-bRpmPhN"},"outputs":[],"source":["transforms_train = albumentations.Compose([\n","    albumentations.Normalize(\n","                mean=[0.485, 0.456, 0.406], # 上のimages /= 255に注意\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0,\n","                p=1.0),\n","    albumentations.Transpose(p=0.5),\n","    albumentations.VerticalFlip(p=0.5),\n","    albumentations.HorizontalFlip(p=0.5),\n","])\n","transforms_val = albumentations.Compose([\n","    albumentations.Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0,\n","                p=1.0),\n","    ])\n","\n","# efficientnetb0\n","# 'mean': (0.485, 0.456, 0.406),\n","#  'std': (0.229, 0.224, 0.225),"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVKMyntrmPeO"},"outputs":[],"source":["# dataset_show = PANDADataset(df_train, image_size, n_tiles, 0, transform=transforms_train)\n","# from pylab import rcParams\n","# rcParams['figure.figsize'] = 20,10\n","# for i in range(2):\n","#     f, axarr = plt.subplots(1,5)\n","#     for p in range(5):\n","#         idx = np.random.randint(0, len(dataset_show))\n","#         img, label = dataset_show[idx]\n","#         axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n","#         axarr[p].set_title(label)\n"]},{"cell_type":"markdown","metadata":{"id":"kUMBHKwEnBRk"},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcGcZi4bmPcD"},"outputs":[],"source":["# labels = ['CC', 'EC', 'HGSC', 'LGSC', 'MC', 'Other'] #df_train['label'].unique().tolist() + ['Other']\n","# pos_weight = torch.tensor([1.0, 3.0, 3.0, 3.0, 1.0], dtype=torch.float32)\n","# pos_weight = pos_weight.to(device)\n","# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","# criterion = nn.CrossEntropyLoss()\n","\n","\n","# criterion = nn.BCEWithLogitsLoss()\n","criterion = ArcFaceLoss(out_dim, 1280)"]},{"cell_type":"markdown","metadata":{"id":"Uz63GDHjnFN7"},"source":["# Train and Val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VzXH5CzmdMT"},"outputs":[],"source":["# def train_epoch(loader, optimizer):\n","\n","#     model.train()\n","#     train_loss = []\n","#     bar = tqdm(loader)\n","#     for (data, target) in bar:\n","\n","#         data, target = data.to(device), target.to(device)\n","#         loss_func = criterion\n","#         optimizer.zero_grad()\n","#         logits = model(data)\n","#         loss = loss_func(logits, target)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         loss_np = loss.detach().cpu().numpy()\n","#         train_loss.append(loss_np)\n","#         smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n","#         bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n","#     return train_loss\n","\n","\n","# prompt: def train_epoch(loader, optimizer):      model.train()     train_loss = []     bar = tqdm(loader)     for (data, target) in bar:          data, target = data.to(device), target.to(device)         loss_func = criterion         optimizer.zero_grad()         logits = model(data)         loss = loss_func(logits, target)         loss.backward()         optimizer.step()          loss_np = loss.detach().cpu().numpy()         train_loss.append(loss_np)         smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)         bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))     return train_lossをtorch.autocast and torch.cuda.amp.GradScalerをつかって書き換えて\n","\n","def train_epoch(loader, optimizer):\n","    model.train()\n","    train_loss = []\n","    bar = tqdm(loader)\n","    scaler = torch.cuda.amp.GradScaler()\n","    for (data, target) in bar:\n","        data, target = data.to(device), target.to(device)\n","        loss_func = criterion\n","        optimizer.zero_grad()\n","        with torch.cuda.amp.autocast():\n","            embeddings = model(data)\n","            loss = loss_func(embeddings, torch.argmax(target, dim=1))\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        loss_np = loss.detach().cpu().numpy()\n","        train_loss.append(loss_np)\n","        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n","        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n","    return train_loss\n","\n","\n","def val_epoch(loader, get_output=False):\n","\n","    model.eval()\n","    val_loss = []\n","    LOGITS = []\n","    PREDS = []\n","    TARGETS = []\n","\n","    with torch.no_grad():\n","        for (data, target) in tqdm(loader):\n","            data, target = data.to(device), target.to(device)\n","            # logits = model(data)\n","            # loss = criterion(logits, target)\n","            # pred = logits.sigmoid().detach()\n","\n","            embeddings = model(data)\n","            loss = criterion(embeddings, torch.argmax(target, dim=1))\n","            logits = criterion.get_logits(embeddings)\n","            pred = logits.sigmoid().detach()\n","\n","\n","\n","            LOGITS.append(logits)\n","            PREDS.append(pred)\n","            TARGETS.append(target)\n","\n","            val_loss.append(loss.detach().cpu().numpy())\n","        val_loss = np.mean(val_loss)\n","\n","    LOGITS = torch.cat(LOGITS).cpu().numpy()\n","    PREDS = torch.cat(PREDS).cpu().numpy()\n","    TARGETS = torch.cat(TARGETS).cpu().numpy()\n","#     acc = (PREDS == TARGETS).mean() * 100.\n","    comp_metric = balanced_accuracy_score(TARGETS.argmax(1), PREDS.argmax(1))\n","    print(comp_metric)\n","\n","#     qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n","#     qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n","#     qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n","#     print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n","\n","    if get_output:\n","        return LOGITS\n","    else:\n","        return val_loss, comp_metric, PREDS\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oa7CxO-hnJir"},"source":["# Create Dataloader & Model & Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zsprurmmdFD"},"outputs":[],"source":["train_idx = np.where((df_train['fold'] != fold))[0]\n","valid_idx = np.where((df_train['fold'] == fold))[0]\n","\n","df_this  = df_train.loc[train_idx]\n","df_valid = df_train.loc[valid_idx]\n","\n","dataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\n","dataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n","\n","train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n","valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n","\n","model = enetv2(enet_type, out_dim=out_dim)\n","model = model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\n","scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\n","scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n","\n","print(len(dataset_train), len(dataset_valid))"]},{"cell_type":"markdown","metadata":{"id":"6W3gPSknnMxE"},"source":["# Run Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuWrVPKMPDj1"},"outputs":[],"source":["def mymetric(df):\n","    cols = df['label'].unique().tolist()\n","    recalls = dict()\n","    for col in cols:\n","        df_ = df.query('label==@col')\n","        recalls[col] = (df_['label']==df_['pred']).sum()/df_.shape[0]\n","    score = 0\n","    for k, v in recalls.items():\n","        score += v\n","    score /= len(cols)\n","    return score, recalls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-SVLiRYmkI9"},"outputs":[],"source":["%%time\n","comp_metric_max = 0.\n","best_file = os.path.join(OUTPUT_EXP, f'{kernel_type}_best_fold{fold}.pth')\n","for epoch in range(1, n_epochs+1):\n","    print(time.ctime(), 'Epoch:', epoch)\n","    scheduler.step(epoch-1)\n","\n","    train_loss = train_epoch(train_loader, optimizer)\n","    val_loss, comp_metric, oof_preds = val_epoch(valid_loader)\n","    df_valid['pred'] = oof_preds.argmax(1)\n","    df_valid['pred'] = df_valid['pred'].map(n2l)\n","\n","    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, balanced accuracy: {(comp_metric):.5f}, '\n","    content += str(mymetric(df_valid))\n","    print(content)\n","    with open(os.path.join(OUTPUT_EXP, f'log_{kernel_type}.txt'), 'a') as appender:\n","        appender.write(content + '\\n')\n","\n","    if comp_metric > comp_metric_max:\n","        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(comp_metric_max, comp_metric))\n","        torch.save(model.state_dict(), best_file)\n","        np.save(os.path.join(OUTPUT_EXP, f'oof_preds_best_fold{fold}.npy'), oof_preds)\n","        comp_metric_max = comp_metric\n","\n","torch.save(model.state_dict(), os.path.join(OUTPUT_EXP, f'{kernel_type}_final_fold{fold}.pth'))\n","np.save(os.path.join(OUTPUT_EXP, f'oof_preds_final_fold{fold}.npy'), oof_preds)\n","print(f'comp metric max {comp_metric_max}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8660gFyo0qA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyPFtGLqnWPR62/WzPDiiB6Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}