{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9chm3EbraQGh"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4Wrt7dVjemI"},"outputs":[],"source":["# prompt: CPUのコア数をしらべて\n","import os\n","os.cpu_count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7YNmSGL1p_5"},"outputs":[],"source":["class Config:\n","    name = \"exp030\" # 実験のたびにコピーしてここの名前を変えて実行するとoutputが別のファイルに保存される\n","\n","    # Colab Env\n","    upload_from_colab = False\n","    api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\"\n","    drive_path = \"/content/drive/MyDrive/kaggle/ucbo\"\n","\n","DEBUG = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbXtfty816RE"},"outputs":[],"source":["import os\n","import json\n","import warnings\n","import shutil\n","import logging\n","import joblib\n","import random\n","import datetime\n","import sys\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhXvf-UB16Ol"},"outputs":[],"source":["COLAB = \"google.colab\" in sys.modules\n","!pip install --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YQXcS4z16IF"},"outputs":[],"source":["if COLAB:\n","    print(\"This environment is Google Colab\")\n","\n","    # mount\n","    from google.colab import drive\n","    if not os.path.isdir(\"/content/drive\"):\n","        drive.mount('/content/drive')\n","\n","\n","    # use kaggle api (need kaggle token)\n","    f = open(Config.api_path, 'r')\n","    json_data = json.load(f)\n","    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n","\n","    # set dirs\n","    DRIVE = Config.drive_path\n","    EXP = Config.name\n","    INPUT = os.path.join(DRIVE, \"Input\")\n","    OUTPUT = os.path.join(DRIVE, \"Output\")\n","    SCRIPT = os.path.join(DRIVE, \"Script\")\n","    OUTPUT_EXP = os.path.join(OUTPUT, EXP)\n","    # EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n","    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n","    # EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n","\n","    # make dirs\n","    for d in [INPUT, SCRIPT, OUTPUT, OUTPUT_EXP]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    # if not os.path.isfile(os.path.join(INPUT, \"train.csv\")):\n","    #     # load dataset\n","    #     ! kaggle competitions download -c UBC-OCEAN -p $INPUT\n","    #     unzip_file = os.path.join(INPUT, 'UBC-OCEAN.zip')\n","    #     ! unzip $unzip_file -d $INPUT\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_aSjd5Zqn9wk"},"outputs":[],"source":["%%time\n","if not DEBUG:\n","    # tmp fileに直接ダウンロードする\n","    TMP = '/content/tmp'\n","    INPUT = '/content/tmp'\n","    !mkdir $TMP\n","    files = [\n","        'tyabanoamami/ucbo-colab-dataset', 'hmendonca/efficientnet-pytorch',\n","            #  'pjmathematician/ucbo-tiles-256-1', #'tyabanoamami/ucbo-clean-images',\n","            #  'pjmathematician/ucbo-tiles-256-2', 'pjmathematician/ucbo-tiles-256-3',\n","            #  'pjmathematician/ucbo-tiles-256-4', 'pjmathematician/ucbo-tiles-256-5',\n","        'jirkaborovec/tiles-of-cancer-2048px-scale-0-25'\n","            ]\n","    for f in files:\n","        !kaggle datasets download -d $f -p $TMP\n","        t = f.split('/')[1]\n","        unzip_file = os.path.join(TMP, f'{t}.zip')\n","        unzip_file_ = TMP + '/' + t\n","        INPUT_ = INPUT + '/' + t\n","        ! unzip $unzip_file -d $unzip_file_\n","        # !mv $unzip_file_ $INPUT_\n","        !rm -rf $unzip_file"]},{"cell_type":"markdown","metadata":{"id":"kP7MT0Q4mssZ"},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dc8KgsmmHvX"},"outputs":[],"source":["!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n","!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4yHEKWS9mF01"},"outputs":[],"source":["import os\n","import sys\n","sys.path = [\n","    os.path.join(INPUT, 'efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master'),\n","] + sys.path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysI2Fw9NjSMp"},"outputs":[],"source":["import time\n","import skimage.io\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import PIL.Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n","from warmup_scheduler import GradualWarmupScheduler\n","from efficientnet_pytorch import model as enet\n","import albumentations\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import cohen_kappa_score\n","from tqdm.notebook import tqdm\n","from sklearn.metrics import balanced_accuracy_score\n","import timm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzV9WLBsNqQi"},"outputs":[],"source":["# df = pd.read_csv('/content/drive/MyDrive/kaggle/ucbo/Input/tiles-of-cancer-2048px-scale-0-25/train.csv')\n","# df[df.image_id==int(folders[1].split('/')[-1])].is_tma.values\n","# from glob import glob\n","# folders = glob('/content/drive/MyDrive/kaggle/ucbo/Input/tiles-of-cancer-2048px-scale-0-25/*')\n","# for f in sorted(folders, key=lambda x: int(x.split('/')[-1]) if x.split('/')[-1]!='train.csv' else 999999)[:-1]:\n","#     tma=False\n","#     if df[df.image_id==int(f.split('/')[-1])].is_tma.values[0]:\n","#         tma=True\n","#     print(f.split('/')[-1], len(glob(f+'/*png')), tma)"]},{"cell_type":"markdown","metadata":{"id":"tOGJTn-Zndmp"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnZ0bZndmKEa"},"outputs":[],"source":["data_dir = os.path.join(INPUT, 'tiles-of-cancer-2048px-scale-0-25')\n","df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","image_folder = os.path.join(data_dir, 'train_images')\n","labels = ['CC', 'EC', 'HGSC', 'LGSC', 'MC', 'Other'] #df_train['label'].unique().tolist() + ['Other']\n","l2n = {v: k for k, v in enumerate(labels)}\n","n2l = {k: v for k, v in enumerate(labels)}\n","\n","kernel_type = Config.name\n","\n","enet_type = 'efficientnet_b0'\n","fold = 0\n","tile_size = 512\n","image_size = 512\n","n_tiles = 4 if DEBUG else 9\n","batch_size = 2\n","num_workers = os.cpu_count()\n","out_dim = 6\n","init_lr = 3e-4\n","warmup_factor = 10\n","\n","warmup_epo = 1\n","n_epochs = 1 if DEBUG else 20\n","df_train = df_train.sample(100).reset_index(drop=True) if DEBUG else df_train\n","\n","device = torch.device('cuda')\n","\n","print(image_folder)\n","\n","import random\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","seed_torch()"]},{"cell_type":"markdown","metadata":{"id":"XKB0VzWDmyce"},"source":["# Create Folds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3mQXsADmPwK"},"outputs":[],"source":["skf = StratifiedKFold(5, shuffle=True, random_state=42)\n","df_train['fold'] = -1\n","for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['label'])):\n","    df_train.loc[valid_idx, 'fold'] = i\n","# df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJ08DLvlmPsr"},"outputs":[],"source":["def get_image_path(image_id:int):\n","    # if 4 <= image_id <= 15188:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-1')\n","    # elif 15209 <= image_id <= 30515:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-2')\n","    # elif 30539 <= image_id <= 38687:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-3')\n","    # elif 38849 <= image_id <= 65300:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-4')\n","    # elif 65371 <= image_id <= 65533:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-5')\n","    path = os.path.join(INPUT, 'tiles-of-cancer-2048px-scale-0-25')\n","    return os.path.join(path, str(image_id))\n","\n","df_train['tile_path'] = df_train['image_id'].apply(lambda x: get_image_path(x))\n","\n","# df_train['total_tiles'] = df_train['tile_path'].apply(lambda x: len(os.listdir(x)))\n","# df_train.head()\n","\n","# train['clean_tiles'] = train['image_id'].apply(lambda x: len(d[x]))/train['total_tiles']\n","# train.head()"]},{"cell_type":"markdown","metadata":{"id":"vDeD5a4Am1xd"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iuIn2_4aqe-0"},"outputs":[],"source":["# prompt: class enetv2(nn.Module):     def __init__(self, backbone, out_dim):         super(enetv2, self).__init__()         self.enet = enet.EfficientNet.from_name(backbone)         self.enet.load_state_dict(torch.load(pretrained_model[backbone]))          self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)         self.enet._fc = nn.Identity()      def extract(self, x):         return self.enet(x)      def forward(self, x):         x = self.extract(x)         x = self.myfc(x)         return xこのモデルをtimmを使って書き直してください\n","class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super(GeM, self).__init__()\n","        self.p = nn.Parameter(torch.ones(1)*p)\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        return self.gem(x, p=self.p, eps=self.eps)\n","\n","    def gem(self, x, p=3, eps=1e-6):\n","        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \\\n","                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n","                ', ' + 'eps=' + str(self.eps) + ')'\n","\n","\n","class enetv2(nn.Module):\n","    def __init__(self, backbone, out_dim):\n","        super(enetv2, self).__init__()\n","        self.enet = timm.create_model(backbone, pretrained=True)\n","        self.myfc = nn.Linear(self.enet.classifier.in_features, out_dim)\n","        self.enet.classifier = nn.Identity()\n","        self.enet.global_pool = nn.Identity()\n","        self.pooling = GeM()\n","\n","    def extract(self, x):\n","        return self.enet(x)\n","\n","    def forward(self, x):\n","        x = self.extract(x)\n","        x = self.pooling(x).flatten(1)\n","        x = self.myfc(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YeLRJnYsqrU"},"outputs":[],"source":["# model = enetv2('efficientnet_b0', 6)\n","# model = timm.create_model('efficientnet_b0', pretrained=True)\n","# model.__dict__['default_cfg']"]},{"cell_type":"markdown","metadata":{"id":"nJ5ihzXsm5CS"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APyXWUI6mPmD"},"outputs":[],"source":["import joblib\n","good_images = joblib.load(os.path.join(OUTPUT, 'bw_checker/good_images.pkl'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAfb99GJmPjE"},"outputs":[],"source":["def get_tiles(paths):\n","    ret = []\n","    for path in paths:\n","        # PNGファイルを読み込み\n","        image = PIL.Image.open(path)\n","\n","        # Pillow ImageオブジェクトをNumPy配列に変換\n","        image_array = np.array(image)\n","        ret.append(image_array)\n","    return ret\n","\n","\n","class PANDADataset(Dataset):\n","    def __init__(self,\n","                 df,\n","                 image_size,\n","                 n_tiles=n_tiles,\n","                 tile_mode=0,\n","                 rand=False,\n","                 transform=None,\n","                ):\n","\n","        self.df = df.reset_index(drop=True)\n","        self.image_size = image_size\n","        self.n_tiles = n_tiles\n","        self.tile_mode = tile_mode\n","        self.rand = rand\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img_id = row.image_id\n","\n","\n","        try:\n","            tiles = good_images[img_id]\n","        except:\n","            files = os.listdir(row.tile_path)\n","            tiles = [row.tile_path + f'/{e}' for e in files]\n","        # if DEBUG:\n","        #     tiles = [t.replace('/content/tmp', INPUT) for t in tiles]\n","        n_imgs = len(tiles)\n","        tiles = get_tiles(tiles)\n","\n","\n","        if self.rand:\n","            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n","        else:\n","            idxes = list(range(self.n_tiles))\n","\n","        n_row_tiles = int(np.sqrt(self.n_tiles))\n","        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n","        for h in range(n_row_tiles):\n","            for w in range(n_row_tiles):\n","                i = h * n_row_tiles + w\n","\n","                # fill all tiles(exp014)\n","                try:\n","                    this_img = tiles[idxes[i%n_imgs]]\n","                except:\n","                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n","                # if len(tiles) > idxes[i]:\n","                #     this_img = tiles[idxes[i]]\n","                # else:\n","                #\n","                this_img = 255 - this_img\n","                if self.transform is not None:\n","                    this_img = self.transform(image=this_img)['image']\n","                h1 = h * image_size\n","                w1 = w * image_size\n","                images[h1:h1+image_size, w1:w1+image_size] = this_img\n","\n","        # if self.transform is not None:\n","        #     images = self.transform(image=images)['image']\n","        images = images.astype(np.float32)\n","        # images /= 255\n","        images = images.transpose(2, 0, 1)\n","\n","        # label = np.zeros(out_dim).astype(np.float32)\n","        # label[l2n[row.label]] = 1.\n","\n","        #label smoothing(exp006)\n","        eps = 0.05\n","        label = np.ones(out_dim).astype(np.float32) * eps/out_dim\n","        label[l2n[row.label]] += (1. - eps)\n","\n","        return torch.tensor(images), torch.tensor(label)\n"]},{"cell_type":"markdown","metadata":{"id":"aZ8pFL5cm9Ta"},"source":["# Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl_I-bRpmPhN"},"outputs":[],"source":["transforms_train = albumentations.Compose([\n","    albumentations.Normalize(\n","                mean=[0.485, 0.456, 0.406], # 上のimages /= 255に注意\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0,\n","                p=1.0),\n","    albumentations.Transpose(p=0.5),\n","    albumentations.VerticalFlip(p=0.5),\n","    albumentations.HorizontalFlip(p=0.5),\n","])\n","transforms_val = albumentations.Compose([\n","    albumentations.Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0,\n","                p=1.0),\n","    ])\n","\n","# efficientnetb0\n","# 'mean': (0.485, 0.456, 0.406),\n","#  'std': (0.229, 0.224, 0.225),"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVKMyntrmPeO"},"outputs":[],"source":["# dataset_show = PANDADataset(df_train, image_size, n_tiles, 0, transform=transforms_train)\n","# from pylab import rcParams\n","# rcParams['figure.figsize'] = 20,10\n","# for i in range(2):\n","#     f, axarr = plt.subplots(1,5)\n","#     for p in range(5):\n","#         idx = np.random.randint(0, len(dataset_show))\n","#         img, label = dataset_show[idx]\n","#         axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n","#         axarr[p].set_title(label)\n"]},{"cell_type":"markdown","metadata":{"id":"kUMBHKwEnBRk"},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcGcZi4bmPcD"},"outputs":[],"source":["criterion = nn.BCEWithLogitsLoss()\n","# criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"Uz63GDHjnFN7"},"source":["# Train and Val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VzXH5CzmdMT"},"outputs":[],"source":["def train_epoch(loader, optimizer):\n","\n","    model.train()\n","    train_loss = []\n","    bar = tqdm(loader)\n","    for (data, target) in bar:\n","\n","        data, target = data.to(device), target.to(device)\n","        loss_func = criterion\n","        optimizer.zero_grad()\n","        logits = model(data)\n","        loss = loss_func(logits, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_np = loss.detach().cpu().numpy()\n","        train_loss.append(loss_np)\n","        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n","        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n","    return train_loss\n","\n","\n","def val_epoch(loader, get_output=False):\n","\n","    model.eval()\n","    val_loss = []\n","    LOGITS = []\n","    PREDS = []\n","    TARGETS = []\n","\n","    with torch.no_grad():\n","        for (data, target) in tqdm(loader):\n","            data, target = data.to(device), target.to(device)\n","            logits = model(data)\n","\n","            loss = criterion(logits, target)\n","\n","            pred = logits.sigmoid().detach()\n","            LOGITS.append(logits)\n","            PREDS.append(pred)\n","            TARGETS.append(target)\n","\n","            val_loss.append(loss.detach().cpu().numpy())\n","        val_loss = np.mean(val_loss)\n","\n","    LOGITS = torch.cat(LOGITS).cpu().numpy()\n","    PREDS = torch.cat(PREDS).cpu().numpy()\n","    TARGETS = torch.cat(TARGETS).cpu().numpy()\n","#     acc = (PREDS == TARGETS).mean() * 100.\n","    comp_metric = balanced_accuracy_score(TARGETS.argmax(1), PREDS.argmax(1))\n","    print(comp_metric)\n","\n","#     qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n","#     qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n","#     qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n","#     print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n","\n","    if get_output:\n","        return LOGITS\n","    else:\n","        return val_loss, comp_metric, PREDS\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oa7CxO-hnJir"},"source":["# Create Dataloader & Model & Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zsprurmmdFD"},"outputs":[],"source":["train_idx = np.where((df_train['fold'] != fold))[0]\n","valid_idx = np.where((df_train['fold'] == fold))[0]\n","\n","df_this  = df_train.loc[train_idx]\n","df_valid = df_train.loc[valid_idx]\n","\n","dataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\n","dataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n","\n","train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n","valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n","\n","model = enetv2(enet_type, out_dim=out_dim)\n","model = model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\n","scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\n","scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n","\n","print(len(dataset_train), len(dataset_valid))"]},{"cell_type":"markdown","metadata":{"id":"6W3gPSknnMxE"},"source":["# Run Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-SVLiRYmkI9"},"outputs":[],"source":["%%time\n","comp_metric_max = 0.\n","best_file = os.path.join(OUTPUT_EXP, f'{kernel_type}_best_fold{fold}.pth')\n","for epoch in range(1, n_epochs+1):\n","    print(time.ctime(), 'Epoch:', epoch)\n","    scheduler.step(epoch-1)\n","\n","    train_loss = train_epoch(train_loader, optimizer)\n","    val_loss, comp_metric, oof_preds = val_epoch(valid_loader)\n","\n","    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, balanced accuracy: {(comp_metric):.5f}'\n","    print(content)\n","    with open(os.path.join(OUTPUT_EXP, f'log_{kernel_type}.txt'), 'a') as appender:\n","        appender.write(content + '\\n')\n","\n","    if comp_metric > comp_metric_max:\n","        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(comp_metric_max, comp_metric))\n","        torch.save(model.state_dict(), best_file)\n","        np.save(os.path.join(OUTPUT_EXP, f'oof_preds_best_fold{fold}.npy'), oof_preds)\n","        comp_metric_max = comp_metric\n","\n","torch.save(model.state_dict(), os.path.join(OUTPUT_EXP, f'{kernel_type}_final_fold{fold}.pth'))\n","np.save(os.path.join(OUTPUT_EXP, f'oof_preds_final_fold{fold}.npy'), oof_preds)\n","print(f'comp metric max {comp_metric_max}')"]},{"cell_type":"code","source":[],"metadata":{"id":"3CDiNHmG_ddR"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMFcB/FA6BLYWu4vZHi5nrH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}