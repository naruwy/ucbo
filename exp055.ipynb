{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1702741563031,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"9chm3EbraQGh","outputId":"089dc034-4722-4476-aeac-14fc3a9fd2d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec 16 15:46:01 2023       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   66C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1702741563032,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"q4Wrt7dVjemI","outputId":"1c5b4072-1264-47c0-868f-be9a8075aeea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":2}],"source":["# prompt: CPUのコア数をしらべて\n","import os\n","os.cpu_count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7YNmSGL1p_5"},"outputs":[],"source":["class Config:\n","    name = \"exp055\" # 実験のたびにコピーしてここの名前を変えて実行するとoutputが別のファイルに保存される\n","\n","    # Colab Env\n","    upload_from_colab = False\n","    api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\"\n","    drive_path = \"/content/drive/MyDrive/kaggle/ucbo\"\n","\n","DEBUG = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbXtfty816RE"},"outputs":[],"source":["import os\n","import json\n","import warnings\n","import shutil\n","import logging\n","import joblib\n","import random\n","import datetime\n","import sys\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6304,"status":"ok","timestamp":1702741569314,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"LhXvf-UB16Ol","outputId":"15d9d311-0ae0-4760-f768-e9f0dcfa887b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kaggle\n","  Downloading kaggle-1.5.16.tar.gz (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m978.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110683 sha256=7be91fd37549a59d79f21ebcbaaa123b07cfa674d7124190ef7ce2c2f8eb4e98\n","  Stored in directory: /root/.cache/pip/wheels/43/4b/fb/736478af5e8004810081a06259f9aa2f7c3329fc5d03c2c412\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.16\n","    Uninstalling kaggle-1.5.16:\n","      Successfully uninstalled kaggle-1.5.16\n","Successfully installed kaggle-1.5.16\n"]}],"source":["COLAB = \"google.colab\" in sys.modules\n","!pip install --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17742,"status":"ok","timestamp":1702741641750,"user":{"displayName":"鳴川彰将","userId":"00422213483226230461"},"user_tz":-540},"id":"1YQXcS4z16IF","outputId":"294a7e6b-0ed2-4e71-a186-5ae34e3d7baf"},"outputs":[{"output_type":"stream","name":"stdout","text":["This environment is Google Colab\n","Mounted at /content/drive\n"]}],"source":["if COLAB:\n","    print(\"This environment is Google Colab\")\n","\n","    # mount\n","    from google.colab import drive\n","    if not os.path.isdir(\"/content/drive\"):\n","        drive.mount('/content/drive')\n","\n","\n","    # use kaggle api (need kaggle token)\n","    f = open(Config.api_path, 'r')\n","    json_data = json.load(f)\n","    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n","\n","    # set dirs\n","    DRIVE = Config.drive_path\n","    EXP = Config.name\n","    INPUT = os.path.join(DRIVE, \"Input\")\n","    OUTPUT = os.path.join(DRIVE, \"Output\")\n","    SCRIPT = os.path.join(DRIVE, \"Script\")\n","    OUTPUT_EXP = os.path.join(OUTPUT, EXP)\n","    # EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n","    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n","    # EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n","\n","    # make dirs\n","    for d in [INPUT, SCRIPT, OUTPUT, OUTPUT_EXP]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    # if not os.path.isfile(os.path.join(INPUT, \"train.csv\")):\n","    #     # load dataset\n","    #     ! kaggle competitions download -c UBC-OCEAN -p $INPUT\n","    #     unzip_file = os.path.join(INPUT, 'UBC-OCEAN.zip')\n","    #     ! unzip $unzip_file -d $INPUT\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aSjd5Zqn9wk","outputId":"98ad8b3a-b38b-4f0b-c934-2260d9c977c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading ucbo-colab-dataset.zip to /content/tmp\n"," 96% 384M/399M [00:04<00:00, 51.2MB/s]\n","100% 399M/399M [00:04<00:00, 90.9MB/s]\n","Archive:  /content/tmp/ucbo-colab-dataset.zip\n","  inflating: /content/tmp/ucbo-colab-dataset/sample_submission.csv  \n","  inflating: /content/tmp/ucbo-colab-dataset/test.csv  \n","  inflating: /content/tmp/ucbo-colab-dataset/train.csv  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/13568.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/17637.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/21020.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/29084.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/31594.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/35565.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/36302.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/36583.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/36783.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/37385.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/40864.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/4134.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/41368.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/41586.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/42857.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/44603.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/47035.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/48734.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/50932.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/53655.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/57696.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/61797.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/8280.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/91.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/train_images/9200.png  \n","  inflating: /content/tmp/ucbo-colab-dataset/updated_image_ids.json  \n","Downloading efficientnet-pytorch.zip to /content/tmp\n"," 98% 673M/688M [00:05<00:00, 145MB/s]\n","100% 688M/688M [00:05<00:00, 130MB/s]\n","Archive:  /content/tmp/efficientnet-pytorch.zip\n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/.gitignore  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/LICENSE  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/efficientnet_pytorch/__init__.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/efficientnet_pytorch/model.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/efficientnet_pytorch/utils.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/imagenet/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/imagenet/data/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/imagenet/main.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/check.ipynb  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/example.ipynb  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/img.jpg  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/img2.jpg  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/examples/simple/labels_map.txt  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/setup.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/README.md  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/download.sh  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/load_tf_weights.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/__init__.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/efficientnet_builder.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/efficientnet_model.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/eval_ckpt_main.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/preprocessing.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/convert_tf_to_pt/original_tf/utils.py  \n","  inflating: /content/tmp/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/tf_to_pytorch/pretrained_tensorflow/download.sh  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b0-08094119.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b2-27687264.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b4-e116e8b3.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b5-586e6cc6.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b6-c76e70fd.pth  \n","  inflating: /content/tmp/efficientnet-pytorch/efficientnet-b7-dcc49843.pth  \n","Downloading tiles-of-cancer-2048px-scale-0-25.zip to /content/tmp\n"," 53% 26.2G/49.4G [04:30<02:35, 161MB/s]"]}],"source":["%%time\n","if not DEBUG:\n","    # tmp fileに直接ダウンロードする\n","    TMP = '/content/tmp'\n","    INPUT = '/content/tmp'\n","    !mkdir $TMP\n","    files = [\n","        'tyabanoamami/ucbo-colab-dataset', 'hmendonca/efficientnet-pytorch',\n","            #  'pjmathematician/ucbo-tiles-256-1', #'tyabanoamami/ucbo-clean-images',\n","            #  'pjmathematician/ucbo-tiles-256-2', 'pjmathematician/ucbo-tiles-256-3',\n","            #  'pjmathematician/ucbo-tiles-256-4', 'pjmathematician/ucbo-tiles-256-5',\n","        'jirkaborovec/tiles-of-cancer-2048px-scale-0-25',\n","    #    'tyabanoamami/ucbo-masktiles-dataset',\n","            ]\n","    for f in files:\n","        !kaggle datasets download -d $f -p $TMP\n","        t = f.split('/')[1]\n","        unzip_file = os.path.join(TMP, f'{t}.zip')\n","        unzip_file_ = TMP + '/' + t\n","        INPUT_ = INPUT + '/' + t\n","        ! unzip $unzip_file -d $unzip_file_\n","        # !mv $unzip_file_ $INPUT_\n","        !rm -rf $unzip_file"]},{"cell_type":"markdown","metadata":{"id":"kP7MT0Q4mssZ"},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dc8KgsmmHvX"},"outputs":[],"source":["!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n","!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4yHEKWS9mF01"},"outputs":[],"source":["import os\n","import sys\n","sys.path = [\n","    os.path.join(INPUT, 'efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master'),\n","] + sys.path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysI2Fw9NjSMp"},"outputs":[],"source":["import time\n","import skimage.io\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import PIL.Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n","from warmup_scheduler import GradualWarmupScheduler\n","from efficientnet_pytorch import model as enet\n","import albumentations\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import cohen_kappa_score\n","from tqdm.notebook import tqdm\n","from sklearn.metrics import balanced_accuracy_score\n","import timm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzV9WLBsNqQi"},"outputs":[],"source":["# df = pd.read_csv('/content/drive/MyDrive/kaggle/ucbo/Input/tiles-of-cancer-2048px-scale-0-25/train.csv')\n","# df[df.image_id==int(folders[1].split('/')[-1])].is_tma.values\n","# from glob import glob\n","# folders = glob('/content/drive/MyDrive/kaggle/ucbo/Input/tiles-of-cancer-2048px-scale-0-25/*')\n","# for f in sorted(folders, key=lambda x: int(x.split('/')[-1]) if x.split('/')[-1]!='train.csv' else 999999)[:-1]:\n","#     tma=False\n","#     if df[df.image_id==int(f.split('/')[-1])].is_tma.values[0]:\n","#         tma=True\n","#     print(f.split('/')[-1], len(glob(f+'/*png')), tma)"]},{"cell_type":"markdown","metadata":{"id":"tOGJTn-Zndmp"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnZ0bZndmKEa"},"outputs":[],"source":["data_dir = os.path.join(INPUT, 'tiles-of-cancer-2048px-scale-0-25')\n","df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","image_folder = os.path.join(data_dir, 'train_images')\n","labels = ['CC', 'EC', 'HGSC', 'LGSC', 'MC', 'Other'] #df_train['label'].unique().tolist() + ['Other']\n","l2n = {v: k for k, v in enumerate(labels)}\n","n2l = {k: v for k, v in enumerate(labels)}\n","\n","kernel_type = Config.name\n","\n","enet_type = 'efficientnet_b0'\n","fold = 0\n","# tile_size = 512\n","image_size = 256\n","n_tiles = 4 if DEBUG else 24\n","batch_size = 8\n","num_workers = os.cpu_count()\n","out_dim = 5\n","init_lr = 3e-4\n","warmup_factor = 10\n","\n","warmup_epo = 1\n","n_epochs = 1 if DEBUG else 4\n","df_train = df_train.sample(100).reset_index(drop=True) if DEBUG else df_train\n","\n","device = torch.device('cuda')\n","\n","print(image_folder)\n","\n","import random\n","def seed_torch(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","seed_torch()"]},{"cell_type":"markdown","metadata":{"id":"XKB0VzWDmyce"},"source":["# Create Folds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3mQXsADmPwK"},"outputs":[],"source":["skf = StratifiedKFold(5, shuffle=True, random_state=42)\n","df_train['fold'] = -1\n","for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['label'])):\n","    df_train.loc[valid_idx, 'fold'] = i\n","# df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJ08DLvlmPsr"},"outputs":[],"source":["def get_image_path(image_id:int):\n","    # if 4 <= image_id <= 15188:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-1')\n","    # elif 15209 <= image_id <= 30515:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-2')\n","    # elif 30539 <= image_id <= 38687:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-3')\n","    # elif 38849 <= image_id <= 65300:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-4')\n","    # elif 65371 <= image_id <= 65533:\n","    #     path = os.path.join(INPUT, 'ucbo-tiles-256-5')\n","    path = os.path.join(INPUT, 'tiles-of-cancer-2048px-scale-0-25')\n","    return os.path.join(path, str(image_id))\n","\n","df_train['tile_path'] = df_train['image_id'].apply(lambda x: get_image_path(x))\n","\n","# df_train['total_tiles'] = df_train['tile_path'].apply(lambda x: len(os.listdir(x)))\n","# df_train.head()\n","\n","# train['clean_tiles'] = train['image_id'].apply(lambda x: len(d[x]))/train['total_tiles']\n","# train.head()"]},{"cell_type":"markdown","metadata":{"id":"vDeD5a4Am1xd"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iuIn2_4aqe-0"},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","\n","# class MishFunction(torch.autograd.Function):\n","#     @ staticmethod\n","#     def forward(ctx, x):\n","#         ctx.save_for_backward(x)\n","#         return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n","\n","#     @ staticmethod １ますあいてる\n","#     def backward(ctx, grad_output):\n","#         x = ctx.saved_variables[0]\n","#         sigmoid = torch.sigmoid(x)\n","#         tanh_sp = torch.tanh(F.softplus(x))\n","#         return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n","\n","# class Mish(nn.Module):\n","#     def forward(self, x):\n","#         return MishFunction.apply(x)\n","\n","# def to_Mish(model):\n","#     for child_name, child in model.named_children():\n","#         if isinstance(child, nn.ReLU):\n","#             setattr(model, child_name, Mish())\n","#         else:\n","#             to_Mish(child)\n","\n","\n","class AdaptiveConcatPool2d(nn.Module):\n","    def __init__(self):\n","        super(AdaptiveConcatPool2d, self).__init__()\n","        self.avg = nn.AdaptiveAvgPool2d(1)\n","        self.max = nn.AdaptiveMaxPool2d(1)\n","    def forward(self, x):\n","        x1 = self.avg(x)\n","        x2 = self.max(x)\n","        x = torch.cat([x1, x2], 1)\n","        return x\n","\n","\n","class Model(nn.Module):\n","    def __init__(self, arch='efficientnet_b0', n=out_dim, pre=True):\n","        super().__init__()\n","        m = timm.create_model(arch, pretrained=pre)\n","        self.enc = nn.Sequential(*list(m.children())[:-2])\n","        nc = list(m.children())[-1].in_features\n","        self.AdaptiveConcatPool2d = AdaptiveConcatPool2d()\n","        self.head = nn.Sequential(AdaptiveConcatPool2d(),nn.Flatten(),nn.Linear(2*nc,512),\n","                            nn.ReLU(),nn.BatchNorm1d(512), nn.Dropout(0.2),nn.Linear(512,n))\n","\n","\n","    def forward(self, x):\n","        shape = x.shape\n","        n = shape[1]\n","        x = x.view(-1,shape[2],shape[3],shape[4])\n","        x = self.enc(x)\n","\n","        shape = x.shape\n","        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n","          .view(-1,shape[1],shape[2]*n,shape[3])\n","        x = self.head(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YeLRJnYsqrU"},"outputs":[],"source":["# model = enetv2('efficientnet_b0', 6)\n","# model = timm.create_model('efficientnet_b0', pretrained=True)\n","# model.__dict__['default_cfg']"]},{"cell_type":"markdown","metadata":{"id":"nJ5ihzXsm5CS"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APyXWUI6mPmD"},"outputs":[],"source":["import joblib\n","good_images = joblib.load(os.path.join(OUTPUT, 'bw_checker/good_images.pkl'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wkrk3r7KZ4ip"},"outputs":[],"source":["if DEBUG:\n","    for k, v in good_images.items():\n","        tiles = [t.replace('/content/tmp', INPUT) for t in v]\n","        good_images[k] = tiles\n","        if len(tiles) < 13:\n","            print(k, len(tiles))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zM28MSKYPdj-"},"outputs":[],"source":["def get_tiles(paths, img_sz):\n","    ret = []\n","    for path in paths:\n","        # PNGファイルを読み込み\n","        image = PIL.Image.open(path).resize((img_sz, img_sz))\n","\n","        # Pillow ImageオブジェクトをNumPy配列に変換\n","        image_array = np.array(image)\n","        ret.append(image_array)\n","    return ret\n","\n","\n","class PANDADataset(Dataset):\n","    def __init__(self,\n","                 df,\n","                 image_size,\n","                 n_tiles=n_tiles,\n","                 tile_mode=0,\n","                 rand=False,\n","                 transform=None,\n","                ):\n","\n","        self.df = df.reset_index(drop=True)\n","        self.image_size = image_size\n","        self.n_tiles = n_tiles\n","        self.tile_mode = tile_mode\n","        self.rand = rand\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img_id = row.image_id\n","\n","\n","        tiles = good_images[img_id]\n","        n_imgs = len(tiles)\n","        tiles = get_tiles(tiles, self.image_size)\n","\n","        if self.rand:\n","            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n","        else:\n","            idxes = list(range(self.n_tiles))\n","\n","        n_row_tiles = int(np.sqrt(self.n_tiles))\n","\n","        images = []\n","        for i in range(self.n_tiles):\n","\n","            try:\n","                this_img = tiles[idxes[i%n_imgs]]\n","            except:\n","                this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n","\n","            this_img = 255 - this_img\n","            if self.transform is not None:\n","                this_img = self.transform(image=this_img)['image']\n","\n","            this_img = this_img.astype(np.float32)\n","            this_img = this_img.transpose(2, 0, 1)\n","            images.append(this_img)\n","\n","\n","        label = np.zeros(out_dim).astype(np.float32)\n","        label[l2n[row.label]] = 1.\n","        return torch.tensor(images), torch.tensor(label)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aZ8pFL5cm9Ta"},"source":["# Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl_I-bRpmPhN"},"outputs":[],"source":["transforms_train = albumentations.Compose([\n","    albumentations.Normalize(\n","                mean=[0.485, 0.456, 0.406], # 上のimages /= 255に注意\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0,\n","                p=1.0),\n","    albumentations.Transpose(p=0.5),\n","    albumentations.VerticalFlip(p=0.5),\n","    albumentations.HorizontalFlip(p=0.5),\n","])\n","transforms_val = albumentations.Compose([\n","    albumentations.Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0,\n","                p=1.0),\n","    ])\n","\n","# efficientnetb0\n","# 'mean': (0.485, 0.456, 0.406),\n","#  'std': (0.229, 0.224, 0.225),"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVKMyntrmPeO"},"outputs":[],"source":["# dataset_show = PANDADataset(df_train, image_size, n_tiles, 0, transform=transforms_train)\n","# from pylab import rcParams\n","# rcParams['figure.figsize'] = 20,10\n","# for i in range(2):\n","#     f, axarr = plt.subplots(1,5)\n","#     for p in range(5):\n","#         idx = np.random.randint(0, len(dataset_show))\n","#         img, label = dataset_show[idx]\n","#         axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n","#         axarr[p].set_title(label)\n"]},{"cell_type":"markdown","metadata":{"id":"kUMBHKwEnBRk"},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcGcZi4bmPcD"},"outputs":[],"source":["# labels = ['CC', 'EC', 'HGSC', 'LGSC', 'MC', 'Other'] #df_train['label'].unique().tolist() + ['Other']\n","# pos_weight = torch.tensor([1.0, 3.0, 3.0, 3.0, 1.0], dtype=torch.float32)\n","# pos_weight = pos_weight.to(device)\n","# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","# criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"Uz63GDHjnFN7"},"source":["# Train and Val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VzXH5CzmdMT"},"outputs":[],"source":["# def train_epoch(loader, optimizer):\n","\n","#     model.train()\n","#     train_loss = []\n","#     bar = tqdm(loader)\n","#     for (data, target) in bar:\n","\n","#         data, target = data.to(device), target.to(device)\n","#         loss_func = criterion\n","#         optimizer.zero_grad()\n","#         logits = model(data)\n","#         loss = loss_func(logits, target)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         loss_np = loss.detach().cpu().numpy()\n","#         train_loss.append(loss_np)\n","#         smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n","#         bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n","#     return train_loss\n","\n","\n","# prompt: def train_epoch(loader, optimizer):      model.train()     train_loss = []     bar = tqdm(loader)     for (data, target) in bar:          data, target = data.to(device), target.to(device)         loss_func = criterion         optimizer.zero_grad()         logits = model(data)         loss = loss_func(logits, target)         loss.backward()         optimizer.step()          loss_np = loss.detach().cpu().numpy()         train_loss.append(loss_np)         smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)         bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))     return train_lossをtorch.autocast and torch.cuda.amp.GradScalerをつかって書き換えて\n","\n","def train_epoch(loader, optimizer):\n","    model.train()\n","    train_loss = []\n","    bar = tqdm(loader)\n","    scaler = torch.cuda.amp.GradScaler()\n","    for (data, target) in bar:\n","        data, target = data.to(device), target.to(device)\n","        loss_func = criterion\n","        optimizer.zero_grad()\n","        with torch.cuda.amp.autocast():\n","            logits = model(data)\n","            loss = loss_func(logits, target)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        loss_np = loss.detach().cpu().numpy()\n","        train_loss.append(loss_np)\n","        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n","        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n","    return train_loss\n","\n","\n","def val_epoch(loader, get_output=False):\n","\n","    model.eval()\n","    val_loss = []\n","    LOGITS = []\n","    PREDS = []\n","    TARGETS = []\n","\n","    with torch.no_grad():\n","        for (data, target) in tqdm(loader):\n","            data, target = data.to(device), target.to(device)\n","            logits = model(data)\n","\n","            loss = criterion(logits, target)\n","\n","            pred = logits.sigmoid().detach()\n","            LOGITS.append(logits)\n","            PREDS.append(pred)\n","            TARGETS.append(target)\n","\n","            val_loss.append(loss.detach().cpu().numpy())\n","        val_loss = np.mean(val_loss)\n","\n","    LOGITS = torch.cat(LOGITS).cpu().numpy()\n","    PREDS = torch.cat(PREDS).cpu().numpy()\n","    TARGETS = torch.cat(TARGETS).cpu().numpy()\n","#     acc = (PREDS == TARGETS).mean() * 100.\n","    comp_metric = balanced_accuracy_score(TARGETS.argmax(1), PREDS.argmax(1))\n","    print(comp_metric)\n","\n","#     qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n","#     qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n","#     qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n","#     print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n","\n","    if get_output:\n","        return LOGITS\n","    else:\n","        return val_loss, comp_metric, PREDS\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oa7CxO-hnJir"},"source":["# Create Dataloader & Model & Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zsprurmmdFD"},"outputs":[],"source":["train_idx = np.where((df_train['fold'] != fold))[0]\n","valid_idx = np.where((df_train['fold'] == fold))[0]\n","\n","df_this  = df_train.loc[train_idx]\n","df_valid = df_train.loc[valid_idx]\n","\n","dataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\n","dataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n","\n","train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n","valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n","\n","model = Model(arch='efficientnet_b0', n=5, pre=True)\n","model = model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\n","scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo, eta_min=1.0e-4)\n","scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n","\n","print(len(dataset_train), len(dataset_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LNkW02hljhy"},"outputs":[],"source":["dataset_train[0][0].shape"]},{"cell_type":"markdown","metadata":{"id":"6W3gPSknnMxE"},"source":["# Run Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuWrVPKMPDj1"},"outputs":[],"source":["def mymetric(df):\n","    cols = df['label'].unique().tolist()\n","    recalls = dict()\n","    for col in cols:\n","        df_ = df.query('label==@col')\n","        recalls[col] = (df_['label']==df_['pred']).sum()/df_.shape[0]\n","    score = 0\n","    for k, v in recalls.items():\n","        score += v\n","    score /= len(cols)\n","    return score, recalls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319,"referenced_widgets":["fc5c60e4186d41d5b4762ffb039bf673","f35a616fecc54b669c421c0fba3d2016","882105048be541f8a3dce6a4bb97aed7","2c01561cddcc41398e8c8c786f40f77c","4ad71786116e46b7bd5995cd59e2ecee","16b13ffd2bb04f558ca776afa0fb6fa7","4530614e2b5845969b5a13c87a282a50","ec32ed241ca7463aa125c013d7c845e6","c68cb058f82e4aaa99779e3ef2a76dd5","f3dc6638d000427c8cbb72ed0ca6ade3","b17a05ced6cc4448961d04a305659ca5","107933ab40f24cf484c3c7ef374d8ced","f3dd2cb653bc41e089cd400dc8a6d072","481c81e14788411591d1dd0c3c6430db","954ad1689b34471f9ff33baff77cd005","d8887fd2a33c431db2b700785af7fc74","228c849852d24dd09340283e25ea1edf","96b9bc0807db4f2dbfa525d97a5bc02a","6d613e7680d6497cbe14b1e7de14ee1c","8460175e9ddf4c78841faa457b0cacbd","188db6a20aa24a7aaead1fd9fdebefd1","195e1e53802a43a7a3881f5fc6b3e68a","fd0673741d7f4df59675b30f2d5dcc8c"]},"id":"A-SVLiRYmkI9","outputId":"edb9e0b5-e800-4bbb-e055-746ef28d1f6d"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Sat Dec 16 16:07:06 2023 Epoch: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc5c60e4186d41d5b4762ffb039bf673","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/54 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/14 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f35a616fecc54b669c421c0fba3d2016"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.4102222222222222\n","Sat Dec 16 16:36:38 2023 Epoch 1, lr: 0.0000300, train loss: 0.70947, val loss: 0.69898, balanced accuracy: 0.41022, (0.4102222222222222, {'HGSC': 0.6, 'CC': 0.1, 'EC': 0.24, 'MC': 0.7777777777777778, 'LGSC': 0.3333333333333333})\n","score2 (0.000000 --> 0.410222).  Saving model ...\n","Sat Dec 16 16:36:38 2023 Epoch: 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/54 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3dd2cb653bc41e089cd400dc8a6d072"}},"metadata":{}}],"source":["%%time\n","comp_metric_max = 0.\n","best_file = os.path.join(OUTPUT_EXP, f'{kernel_type}_best_fold{fold}.pth')\n","for epoch in range(1, n_epochs+1):\n","    print(time.ctime(), 'Epoch:', epoch)\n","    scheduler.step(epoch-1)\n","\n","    train_loss = train_epoch(train_loader, optimizer)\n","    val_loss, comp_metric, oof_preds = val_epoch(valid_loader)\n","    df_valid['pred'] = oof_preds.argmax(1)\n","    df_valid['pred'] = df_valid['pred'].map(n2l)\n","\n","    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, balanced accuracy: {(comp_metric):.5f}, '\n","    content += str(mymetric(df_valid))\n","    print(content)\n","    with open(os.path.join(OUTPUT_EXP, f'log_{kernel_type}.txt'), 'a') as appender:\n","        appender.write(content + '\\n')\n","\n","    if comp_metric > comp_metric_max:\n","        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(comp_metric_max, comp_metric))\n","        torch.save(model.state_dict(), best_file)\n","        np.save(os.path.join(OUTPUT_EXP, f'oof_preds_best_fold{fold}.npy'), oof_preds)\n","        comp_metric_max = comp_metric\n","\n","torch.save(model.state_dict(), os.path.join(OUTPUT_EXP, f'{kernel_type}_final_fold{fold}.pth'))\n","np.save(os.path.join(OUTPUT_EXP, f'oof_preds_final_fold{fold}.npy'), oof_preds)\n","print(f'comp metric max {comp_metric_max}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8660gFyo0qA"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idnzmKyCX0CP"},"outputs":[],"source":["#gpu 14GB"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyPiWZrGPZavQ5kIiRCoFJr0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f35a616fecc54b669c421c0fba3d2016":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_882105048be541f8a3dce6a4bb97aed7","IPY_MODEL_2c01561cddcc41398e8c8c786f40f77c","IPY_MODEL_4ad71786116e46b7bd5995cd59e2ecee"],"layout":"IPY_MODEL_16b13ffd2bb04f558ca776afa0fb6fa7"}},"882105048be541f8a3dce6a4bb97aed7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4530614e2b5845969b5a13c87a282a50","placeholder":"​","style":"IPY_MODEL_ec32ed241ca7463aa125c013d7c845e6","value":"100%"}},"2c01561cddcc41398e8c8c786f40f77c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c68cb058f82e4aaa99779e3ef2a76dd5","max":14,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3dc6638d000427c8cbb72ed0ca6ade3","value":14}},"4ad71786116e46b7bd5995cd59e2ecee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b17a05ced6cc4448961d04a305659ca5","placeholder":"​","style":"IPY_MODEL_107933ab40f24cf484c3c7ef374d8ced","value":" 14/14 [06:16&lt;00:00, 19.22s/it]"}},"16b13ffd2bb04f558ca776afa0fb6fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4530614e2b5845969b5a13c87a282a50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec32ed241ca7463aa125c013d7c845e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c68cb058f82e4aaa99779e3ef2a76dd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3dc6638d000427c8cbb72ed0ca6ade3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b17a05ced6cc4448961d04a305659ca5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"107933ab40f24cf484c3c7ef374d8ced":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3dd2cb653bc41e089cd400dc8a6d072":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_481c81e14788411591d1dd0c3c6430db","IPY_MODEL_954ad1689b34471f9ff33baff77cd005","IPY_MODEL_d8887fd2a33c431db2b700785af7fc74"],"layout":"IPY_MODEL_228c849852d24dd09340283e25ea1edf"}},"481c81e14788411591d1dd0c3c6430db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96b9bc0807db4f2dbfa525d97a5bc02a","placeholder":"​","style":"IPY_MODEL_6d613e7680d6497cbe14b1e7de14ee1c","value":"loss: 0.68606, smth: 0.67436:  11%"}},"954ad1689b34471f9ff33baff77cd005":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8460175e9ddf4c78841faa457b0cacbd","max":54,"min":0,"orientation":"horizontal","style":"IPY_MODEL_188db6a20aa24a7aaead1fd9fdebefd1","value":6}},"d8887fd2a33c431db2b700785af7fc74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_195e1e53802a43a7a3881f5fc6b3e68a","placeholder":"​","style":"IPY_MODEL_fd0673741d7f4df59675b30f2d5dcc8c","value":" 6/54 [02:38&lt;16:49, 21.03s/it]"}},"228c849852d24dd09340283e25ea1edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96b9bc0807db4f2dbfa525d97a5bc02a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d613e7680d6497cbe14b1e7de14ee1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8460175e9ddf4c78841faa457b0cacbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"188db6a20aa24a7aaead1fd9fdebefd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"195e1e53802a43a7a3881f5fc6b3e68a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd0673741d7f4df59675b30f2d5dcc8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}